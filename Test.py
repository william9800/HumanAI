import torch
import torchvision.transforms as transforms
from dataset.dataset import HumanAI
from efficientnet_pytorch import EfficientNet

# è®¾å¤‡é€‰æ‹©
DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# é¢„å¤„ç†
transform_test = transforms.Compose([
    transforms.CenterCrop(600),  # EfficientNet-B7æ¨èå°ºå¯¸
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# é‡æ–°æ„é€ æ¨¡å‹å¹¶åŠ è½½å‚æ•°
model = EfficientNet.from_pretrained('efficientnet-b7')
num_ftrs = model._fc.in_features
model._fc = torch.nn.Linear(num_ftrs, 2)  # é€‚é…äºŒåˆ†ç±»
model.load_state_dict(torch.load("model_final.pth"))  # åŠ è½½æƒé‡
model.to(DEVICE)
model.eval()

# é¢„æµ‹ç±»åˆ«åç§°
classes = ( "real", "fake")

# åŠ è½½æµ‹è¯•é›†
dataset_test = HumanAI('data/test/', transforms=transform_test, test=True)

if len(dataset_test) == 0:
    raise ValueError("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ `data/test/` æ˜¯å¦æœ‰å›¾ç‰‡ï¼")

print(f"ğŸ“Œ æµ‹è¯•é›†ä¸­å…±æœ‰ {len(dataset_test)} å¼ å›¾ç‰‡")

# é¢„æµ‹
for index, (img, label) in enumerate(dataset_test):
    img = img.unsqueeze(0).to(DEVICE)  # ç¡®ä¿æ˜¯ [1, C, H, W]
    output = model(img)
    _, pred = torch.max(output, 1)

    print(f'ğŸ“· å›¾åƒ: {dataset_test.imgs[index]}, é¢„æµ‹ç±»åˆ«: {classes[pred.item()]}')
